{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwhbY6M0nKPSjkQ7Y+YziI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smallrus-web/AZSII_prz6/blob/main/%D0%90%D1%80%D1%85%D0%B8%D0%BF%D0%BE%D0%B2_%D0%94%D0%BC%D0%B8%D1%82%D1%80%D0%B8%D0%B9_prz6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Группа: ББМО-01-23\n",
        "\n",
        "Студент: Архипов Дмитрий Евгеньевич\n",
        "\n"
      ],
      "metadata": {
        "id": "acQh6RK6n3GT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.  Загрузка обученной модели и данных MNIST**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3ral3zsvoZcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Загрузка данных MNIST\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Нормализация данных\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Преобразование меток в one-hot encoding\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Модель 1: Простая полносвязная нейронная сеть\n",
        "model1 = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Компиляция модели\n",
        "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Обучение модели\n",
        "model1.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "# Сохранение модели\n",
        "model1.save('mnist_model1.h5')\n",
        "\n",
        "# Модель 2: Свёрточная нейронная сеть (CNN)\n",
        "# Добавление дополнительной размерности для каналов\n",
        "train_images_cnn = train_images.reshape(-1, 28, 28, 1)\n",
        "test_images_cnn = test_images.reshape(-1, 28, 28, 1)\n",
        "\n",
        "model2 = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Компиляция модели\n",
        "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Обучение модели\n",
        "model2.fit(train_images_cnn, train_labels, epochs=5)\n",
        "\n",
        "# Сохранение модели\n",
        "model2.save('mnist_model2.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTQk7Xj6m7Jx",
        "outputId": "575da0a2-bfbd-48e1-bf90-491012a64925"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8789 - loss: 0.4350\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9634 - loss: 0.1255\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9765 - loss: 0.0792\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.0592\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.0439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 23ms/step - accuracy: 0.9132 - loss: 0.2969\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 23ms/step - accuracy: 0.9830 - loss: 0.0548\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - accuracy: 0.9906 - loss: 0.0315\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 22ms/step - accuracy: 0.9934 - loss: 0.0217\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 23ms/step - accuracy: 0.9961 - loss: 0.0138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Реализация атаки FGSM на первую модель**\n"
      ],
      "metadata": {
        "id": "xxXWt3Lhjbjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Функция FGSM атаки\n",
        "def fgsm_attack(image, epsilon, gradient):\n",
        "    # Применение знака градиента к изображению\n",
        "    perturbed_image = image + epsilon * np.sign(gradient)\n",
        "    perturbed_image = np.clip(perturbed_image, 0, 1)  # Убедиться, что значения остаются в пределах [0, 1]\n",
        "    return perturbed_image\n",
        "\n",
        "# Генерация противоречивых примеров для модели\n",
        "def generate_fgsm_adversarial(model, images, labels, epsilon):\n",
        "    adversarial_images = []\n",
        "\n",
        "    for i in range(len(images)):\n",
        "        image = tf.convert_to_tensor(images[i].reshape(1, 28, 28, 1), dtype=tf.float32)  # Преобразование в tensor\n",
        "        label = tf.convert_to_tensor(labels[i].reshape(1, 10), dtype=tf.float32)  # Преобразование метки в tensor\n",
        "\n",
        "        # Вычисление градиента\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(image)  # Отслеживание изменений изображения\n",
        "            prediction = model(image)  # Прогноз от модели\n",
        "            loss = tf.keras.losses.categorical_crossentropy(label, prediction)  # Потери\n",
        "        gradient = tape.gradient(loss, image)  # Градиент потерь относительно изображения\n",
        "\n",
        "        # Генерация атакующего изображения\n",
        "        adv_image = fgsm_attack(image.numpy(), epsilon, gradient.numpy())  # Преобразуем в numpy\n",
        "        adversarial_images.append(adv_image.reshape(28, 28))  # Добавляем изображение в список\n",
        "\n",
        "    return np.array(adversarial_images)\n",
        "\n",
        "# Генерация противоречивых примеров для первой модели\n",
        "epsilon = 0.1\n",
        "adversarial_images_model1 = generate_fgsm_adversarial(model1, test_images, test_labels, epsilon)"
      ],
      "metadata": {
        "id": "eUSOcoNHfrbQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Оценка противоречивых примеров на обеих моделях**\n"
      ],
      "metadata": {
        "id": "rpZ7CoQJjaSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Оценка первой модели на противоречивых примерах\n",
        "test_labels_argmax = np.argmax(test_labels, axis=1) # Преобразование onehot меток в целые числа\n",
        "loss1, acc1 = model1.evaluate(adversarial_images_model1, test_labels)\n",
        "print(f'Accuracy of model1 on adversarial examples: {acc1}')\n",
        "# Оценка второй модели на противоречивых примерах (перенос атаки)\n",
        "adversarial_images_model1_reshaped = adversarial_images_model1.reshape(-1,\n",
        "28, 28, 1)\n",
        "loss2, acc2 = model2.evaluate(adversarial_images_model1_reshaped,\n",
        "test_labels)\n",
        "print(f'Accuracy of model2 on adversarial examples from model1: {acc2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyqADcIghkkd",
        "outputId": "4ddcd31a-f1d3-4de1-a153-11181041cff8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0787 - loss: 7.0997\n",
            "Accuracy of model1 on adversarial examples: 0.10090000182390213\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9488 - loss: 0.1605\n",
            "Accuracy of model2 on adversarial examples from model1: 0.9567999839782715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Оценка модели на противоречивых примерах**\n"
      ],
      "metadata": {
        "id": "kN9KYUsMjX9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерация противоречивых примеров для второй модели\n",
        "adversarial_images_model2 = generate_fgsm_adversarial(model2,\n",
        "test_images.reshape(-1, 28, 28, 1), test_labels, epsilon)\n",
        "# Оценка первой модели на противоречивых примерах второй модели\n",
        "loss3, acc3 = model1.evaluate(adversarial_images_model2.reshape(-1, 28,\n",
        "28), test_labels)\n",
        "print(f'Accuracy of model1 on adversarial examples from model2: {acc3}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCzx4xKZh0b2",
        "outputId": "c51f88dc-26d1-4f6f-e7b7-d1b80c87d490"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8504 - loss: 0.4549\n",
            "Accuracy of model1 on adversarial examples from model2: 0.8680999875068665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод**\n"
      ],
      "metadata": {
        "id": "tAbKeiHnjPlO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Модель model1 продемонстрировала точность 85.04% на стандартных (не атакующих) изображениях из набора данных MNIST.\n",
        "Когда модель была протестирована на противоречивых примерах, созданных с использованием FGSM атаки, точность составила 86.81%.\n",
        "Этот результат предполагает, что модель на этих атакующих примерах показала чуть большую точность, чем на стандартных, что может указывать на то, что атака не вносит значительных изменений в изображения при текущем параметре epsilon или модель хорошо справляется с такими небольшими искажениями."
      ],
      "metadata": {
        "id": "kAovP1YTjM8-"
      }
    }
  ]
}